import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
import uuid
from urllib.parse import urljoin

st.title("üõ†Ô∏è Product Scraper")
st.write("‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏ä‡∏∑‡πà‡∏≠ + ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û) ‡∏à‡∏≤‡∏Å 39 ‡∏´‡∏ô‡πâ‡∏≤")

if st.button("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"):
    headers = {'User-Agent': 'Mozilla/5.0'}
    all_products = []
    os.makedirs("images", exist_ok=True)

    progress = st.progress(0)

    for page in range(1, 40):
        url = f'https://hsc-spareparts.com/products/{page}.html'
        st.write(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏´‡∏ô‡πâ‡∏≤ {page}...")

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
        except Exception as e:
            st.warning(f"‚ùå ‡∏´‡∏ô‡πâ‡∏≤ {page} ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {e}")
            continue

        soup = BeautifulSoup(response.text, 'html.parser')
        product_blocks = soup.select('div.col-md-3.col-sm-4.col-xs-6')

        if not product_blocks:
            st.info(f"‚ÑπÔ∏è ‡∏´‡∏ô‡πâ‡∏≤ {page} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤")
            continue

        for block in product_blocks:
            img = block.find('img')
            name = block.find('p')

            image_url = img['src'] if img and 'src' in img.attrs else 'N/A'
            full_image_url = urljoin(url, image_url)
            product_name = name.text.strip() if name else 'N/A'
            image_filename = f"{uuid.uuid4().hex}_{os.path.basename(full_image_url)}"

            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            try:
                img_data = requests.get(full_image_url, headers=headers).content
                with open(os.path.join("images", image_filename), 'wb') as f:
                    f.write(img_data)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {full_image_url} - {e}")
                image_filename = 'N/A'

            all_products.append({
                'Product Name': product_name,
                'Image URL': full_image_url,
                'Image File': image_filename
            })

        progress.progress(page / 39)

    df = pd.DataFrame(all_products)
    st.success("‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    st.dataframe(df)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    st.subheader("üîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤")
    for product in all_products[:5]:
        image_path = os.path.join("images", product['Image File'])
        if os.path.exists(image_path):
            st.image(image_path, caption=product['Product Name'])

    # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV", csv, "products.csv", "text/csv")
